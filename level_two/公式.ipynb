{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f \\left( x - \\epsilon f'(x) \\right) < f(x) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单层感应器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数 \n",
    "𝐿\n",
    "L：\n",
    "\n",
    "$$ L = \\frac{1}{2} (Y - y)^2 $$\n",
    "预测值 \n",
    "𝑦\n",
    "y 的定义：\n",
    "\n",
    "$$ y = f(wx + b) = \\text{sign}(wx + b) $$\n",
    "基于梯度下降法的参数更新公式：\n",
    "\n",
    "$$ w_{t+1} = w_t + \\Delta w = w_t - \\tau \\frac{\\partial L}{\\partial w} = w_t - \\tau \\frac{\\partial L}{\\partial y} \\frac{\\partial y}{\\partial w} $$\n",
    "更新公式的近似形式：\n",
    "\n",
    "$$ w_{t+1} \\approx w_t + \\tau (Y - y) x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层感知器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 某一层的x与y是非线性关系\n",
    "- 某一层的x与上一层的y是线性关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_j = \\sum_k w_{ji}^l y_i^{l-1} + \\theta_j^l $$\n",
    "\n",
    "\n",
    "$$ y_j = f(x_j) $$\n",
    "其中 𝑓 表示激活函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变量说明\n",
    "- \\( w_{ji}^l \\)：第 \\( l-1 \\) 层第 \\( i \\) 个神经元到第 \\( l \\) 层第 \\( j \\) 个神经元的权重。\n",
    "- \\( x_j \\)：第 \\( l \\) 层第 \\( j \\) 个神经元的输入。\n",
    "- \\( y_j \\)：第 \\( l \\) 层第 \\( j \\) 个神经元的输出。\n",
    "- \\( \\theta_j^l \\)：第 \\( l \\) 层第 \\( j \\) 个神经元的偏置。\n",
    "- \\( C \\)：损失函数（代价函数）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "当前层的误差项 \n",
    "$$ \\delta_j^l = \\frac{\\partial C}{\\partial x_j^l} = \\sum_i \\frac{\\partial C}{\\partial x_i^{l+1}} \\frac{\\partial x_i^{l+1}}{\\partial x_j^l} = \\sum_i \\delta_i^{l+1} \\frac{\\partial x_i^{l+1}}{\\partial x_j^l} $$\n",
    "\n",
    "上一层神经元输入 \n",
    "$$ x_i^{l+1} = \\sum_j w_{ji}^l y_j^l + \\theta_i^{l+1} $$\n",
    "\n",
    "导数项\n",
    "$$ \\frac{\\partial x_i^{l+1}}{\\partial x_j^l} = w_{ji}^l f'(x_j^l) $$\n",
    "\n",
    "变量说明\n",
    "- \\( \\delta_j^l \\)：第 \\( l \\) 层第 \\( j \\) 个神经元的误差项。\n",
    "- \\( C \\)：损失函数。\n",
    "- \\( x_j^l \\)：第 \\( l \\) 层第 \\( j \\) 个神经元的输入。\n",
    "- \\( x_i^{l+1} \\)：第 \\( l+1 \\) 层第 \\( i \\) 个神经元的输入。\n",
    "- \\( y_j^l \\)：第 \\( l \\) 层第 \\( j \\) 个神经元的输出。\n",
    "- \\( w_{ji}^l \\)：第 \\( l \\) 层第 \\( j \\) 个神经元到第 \\( l+1 \\) 层第 \\( i \\) 个神经元的权重。\n",
    "- \\( \\theta_i^{l+1} \\)：第 \\( l+1 \\) 层第 \\( i \\) 个神经元的偏置。\n",
    "- \\( f'(x_j^l) \\)：激活函数 \\( f \\) 对输入 \\( x_j^l \\) 的导数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 误差项递推公式：\n",
    "$$ \\delta_j^l = \\sum_i w_{ji}^{l+1} \\delta_i^{l+1} f'(x_j^l) $$\n",
    "\n",
    "- 当前层的误差项由上一层神经元的误差项加权和计算得到，同时乘以激活函数的梯度。\n",
    "- f'：激活函数的倒数\n",
    "- 误差值：$$ \\delta_j^l $$\n",
    "\n",
    "\n",
    "### 损失函数对权重的偏导数\n",
    "$$ \\frac{\\partial C}{\\partial w_{ji}} = \\delta_j^l y_i^{l-1} $$\n",
    "\n",
    "- 算出某一节点的梯度\n",
    "\n",
    "### 权重更新公式 (我们最终需要的)\n",
    "$$ w_{ji} = w_{ji} - \\eta \\frac{\\partial C}{\\partial w_{ji}} = w_{ji} - \\eta \\delta_j^l y_i^{l-1} $$\n",
    "\n",
    "其中 𝜂 是学习率，表示更新步长。\n",
    "\n",
    "\n",
    "\n",
    "- \\( \\delta_j^l \\)：第 \\( l \\) 层第 \\( j \\) 个神经元的误差项。\n",
    "- \\( w_{ji}^{l+1} \\)：第 \\( l+1 \\) 层第 \\( j \\) 个神经元到第 \\( l+1 \\) 层第 \\( i \\) 个神经元的权重。\n",
    "- \\( f'(x_j^l) \\)：激活函数 \\( f \\) 对第 \\( l \\) 层第 \\( j \\) 个神经元输入 \\( x_j^l \\) 的梯度。\n",
    "- \\( \\eta \\)：学习率，用于控制每次更新的步长。\n",
    "- \\( y_i^{l-1} \\)：第 \\( l-1 \\) 层第 \\( i \\) 个神经元的输出。\n",
    "- \\( C \\)：损失函数，表示模型的误差。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
